# -*- coding: utf-8 -*-
"""IMDB Selection des données.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UhJ15bjE1Mob_ZzN5uFZomTqPAj6DB6b

##Importations
"""


"""##API IMDbPY

Dataset IMDb
"""

import pandas as pd
dataseries=pd.read_csv('series_data.csv')
datafilms=pd.read_csv('films_data.csv')

#dataseries
#datafilms
from imdb import IMDb
plat=IMDb()
nonmis=['The Chosen', 'Wentworth', 'Assasination Classroom']
idseries=[i for i in dataseries['id']]
epserie={}
erreurs=[]
nberreur=0
eta=0
for nom in nonmis:
  eta+=1
  idS=dataseries.loc[dataseries['title']== nom, 'id'].values[0]
  print(idS)
  titre=dataseries.loc[dataseries['id']== idS, 'title'].values[0]
  try:
      print(f"{titre}    {eta}/{len(idseries)}")
      serie = plat.get_movie(idS[2:])
      nomS=serie['localized title']
      plat.update(serie, 'episodes')
      episodes=serie.data['episodes']
      for i in episodes.keys():
        for j in episodes[i].values():
          if (nomS, idS) in epserie.keys():
            epserie[(nomS, idS)].append('tt'+j.movieID)
          else:
            epserie[(nomS, idS)]=['tt'+j.movieID]
  except Exception as e:
      print(titre+'--------------------------------------------------Erreur', e)
      erreurs.append(titre)
      nberreur+=1
      continue

print(epserie)
print(nberreur)
print(erreurs)
episodes_data=pd.DataFrame.from_dict(epserie, orient="index")
episodes_data.to_csv("episodes_enplus.csv")



'''

epserie=pd.read_csv('episodes_data.csv')
epserie[epserie.columns[0]] = epserie[epserie.columns[0]].apply(literal_eval)

# Création du dictionnaire en conservant les tuples comme clés
epserie = epserie.set_index(epserie.columns[0]).apply(lambda row: row.dropna().tolist(), axis=1).to_dict()
present=[]
ddd=0
eta=0
manuel=[]
idseries = []
cleserie=list(epserie.keys())
idtotserie=[]
for j in cleserie:
    idtotserie.append(j[1])
seriesnnft=[]
for i in nomseries:
    eta+=1
    try:
        films = plat.search_movie(i)
        idfilm = films[0].movieID
        print(f"{films[0]}    {eta}/{2000}")
        if 'tt'+idfilm not in idtotserie:
            seriesnnft.append(i)
    except Exception:
        print(i)
        ddd+=1
        manuel.append(i)


epserie2={}
nberr=0
eta=0
manuelep=[]
for titre in seriesnnft:
    eta+=1
    try:
        print(f"{titre}    {eta}/{2000-1574}")
        serie = plat.search_movie(titre)
        serie = serie[0]
        series = plat.get_movie(serie.movieID)
        nomS = series['localized title']
        plat.update(series, 'episodes')
        episodes = series.data['episodes']
        for i in episodes.keys():
            for j in episodes[i].values():
                if (nomS, 'tt' + serie.movieID) in epserie.keys():
                    epserie[(nomS, 'tt' + serie.movieID)].append('tt' + j.movieID)
                else:
                    epserie[(nomS, 'tt' + serie.movieID)] = ['tt' + j.movieID]
    except Exception:
        manuelep.append(titre)
        nberr+=1

episodes_data=pd.DataFrame.from_dict(epserie2, orient="index")
episodes_data.to_csv("episodes_etape2.csv")
print('ddd', ddd)
print("nomseries", len(nomseries))
print("manuel 1", manuel)
print(len(manuel))
print("manuel 2",manuelep)
print(len(manuelep))



'''